{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WCY_p759M_3",
        "colab_type": "code",
        "outputId": "2b7204c6-7925-4d70-d1f6-34681bde69c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/My Drive/Colab Notebooks/NNLP\n",
        "%ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "/content/gdrive/My Drive/Colab Notebooks/NNLP\n",
            " assignment22.ipynb\n",
            " assignment2.ipynb\n",
            " assignment3.ipynb\n",
            " assignment4.ipynb\n",
            " classifier_doc_embeddings.py\n",
            " classifier_ffnn.py\n",
            " classifier_lr.py\n",
            " classifier_word_embeddings.py\n",
            " comments.tsv\n",
            "'Copy of 01_seminar_starter.ipynb'\n",
            "'Copy of sem_28_11.ipynb'\n",
            " d2v.model\n",
            " elmo_2x2048_256_2048cnn_1xhighway_options.json\n",
            " elmo_2x2048_256_2048cnn_1xhighway_weights.hdf5\n",
            " file2_ff.tsv\n",
            " file2.tsv\n",
            " file3.tsv\n",
            " file_ll.tsv\n",
            " file_l.tsv\n",
            " file_sk_lr.tsv\n",
            " \u001b[0m\u001b[01;34mFILIMDB\u001b[0m/\n",
            " glove.6B.300d.txt\n",
            " lstm_text_classification.ipynb\n",
            " Nikolay_Shvetsov_assignment2.ipynb\n",
            " \u001b[01;34mProject\u001b[0m/\n",
            " \u001b[01;34m__pycache__\u001b[0m/\n",
            " stomack.zip\n",
            " tut1-model\n",
            " tut1-model_last.pt\n",
            " tut1-model.pt\n",
            " Untitled0.ipynb\n",
            "'Копия assignment4.ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcYHJCLI84wO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "outputId": "95f29b6a-8f77-4bcf-e8e2-3e49323faf71"
      },
      "source": [
        "!pip install transformers==2.1.1 \n",
        "!pip install tensorboard==1.9\n",
        "# !pip install pytorch_pretrained_bert\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/f9/51824e40f0a23a49eab4fcaa45c1c797cbf9761adedd0b558dab7c958b34/transformers-2.1.1-py3-none-any.whl (311kB)\n",
            "\r\u001b[K     |█                               | 10kB 18.5MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 92kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (4.28.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 52.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (2019.12.9)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (1.10.40)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 41.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.1.1) (1.17.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.1) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.1) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.1.1) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1.1) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1.1) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.1.1) (0.14.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.1.1) (1.13.40)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.1.1) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers==2.1.1) (0.9.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->transformers==2.1.1) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->transformers==2.1.1) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=d7a88aec061efd44a84c14c7f7b8e73983ebcaf4ced659f372d14726605bed40\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.35 sentencepiece-0.1.85 transformers-2.1.1\n",
            "Collecting tensorboard==1.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/1f/3da43860db614e294a034e42d4be5c8f7f0d2c75dc1c428c541116d8cdab/tensorboard-1.9.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 1.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.9) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.9) (1.17.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.9) (0.33.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.9) (3.1.1)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.9) (3.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard==1.9) (0.16.0)\n",
            "Requirement already satisfied: setuptools>=36 in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard==1.9) (42.0.2)\n",
            "\u001b[31mERROR: tensorflow 1.15.0 has requirement tensorboard<1.16.0,>=1.15.0, but you'll have tensorboard 1.9.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "Successfully installed tensorboard-1.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wBMbWgO-9T5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "c07469b2-a255-4d4b-e6ab-17aa95c303af"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel, BertConfig#,BertForSequenceClassification\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "import codecs\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import seaborn as sns\n",
        "import string\n",
        "from time import time\n",
        "import string \n",
        "%matplotlib inline\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.utils.data as data_utils\n",
        "from transformers import BertTokenizer"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPnaoJOUAwr4",
        "colab_type": "code",
        "outputId": "c3578dbe-e2cd-435a-ba4c-7b29a98fe9c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 5740012.36B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkGOLNx3A_F-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "translator = str.maketrans('', '', string.punctuation)\n",
        "\n",
        "def surround_non_symbols(word):\n",
        "    new_word=''\n",
        "    list_letters=list(word)    \n",
        "    for symbol in list_letters:\n",
        "        if symbol in set(string.punctuation):\n",
        "            symbol=' '+symbol+' '\n",
        "        else:\n",
        "            symbol=symbol\n",
        "        new_word+=symbol\n",
        "    return new_word\n",
        "    \n",
        "\n",
        "def preprocess_text(Text,punct=False,figures=False):\n",
        "    result=[]\n",
        "    for sentense in Text:\n",
        "        string=(sentense.lower())\n",
        "        string = \" \".join([surround_non_symbols(word) for word in string.split()])\n",
        "        clear_sentence=\" \".join(string.split())\n",
        "        if punct==True:\n",
        "            clear_sentence=clear_sentence.translate(translator)\n",
        "        if figures==True:\n",
        "            clear_sentence=re.sub(r'\\d+', '', clear_sentence)\n",
        "        result.append(clear_sentence)\n",
        "    return result\n",
        "\n",
        "def tokenization(data):\n",
        "    data_tok =[line.split() for line in tqdm(data)]\n",
        "    return data_tok\n",
        "\n",
        "def text_readers(path):\n",
        "    file=codecs.open(path,'r','utf_8_sig')\n",
        "    text=file.read()\n",
        "    file.close()\n",
        "    text=text.split('\\n')\n",
        "    text=text[:-1]\n",
        "    return text\n",
        "\n",
        "train_labels=pd.read_csv('FILIMDB/train.labels',header=None)\n",
        "dev_labels=pd.read_csv('FILIMDB/dev.labels',header=None)\n",
        "dev_labels_b=pd.read_csv('FILIMDB/dev-b.labels',header=None)\n",
        "\n",
        "train_text=text_readers('FILIMDB/train.texts')\n",
        "dev=text_readers('FILIMDB/dev.texts')\n",
        "test=text_readers('FILIMDB/test.texts')\n",
        "dev_b=text_readers('FILIMDB/dev-b.texts')\n",
        "test_b=text_readers('FILIMDB/test-b.texts')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdNOd0tkBMwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_tokens=preprocess_text(train_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNZFzMspDDal",
        "colab_type": "code",
        "outputId": "7ff2e7ab-0e12-4c31-998d-66bb4cc3ce78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "bert_tokens=tokenizer.tokenize(train_tokens[0])\n",
        "bert_tokens_subtoken_idxs = tokenizer.convert_tokens_to_ids(bert_tokens)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (561 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrlq9lmUDO1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mask creation\n",
        "def bpe_tokenize(bpe_tokenizer, words):\n",
        "    new_words = []\n",
        "    bpe_masks = []\n",
        "    pad_token = '[PAD]'\n",
        "    toks=bpe_tokenizer.tokenize(words)\n",
        "    if len(toks)<512:\n",
        "      pad_size=512-len(toks)\n",
        "      toks=toks+pad_size*[pad_token]\n",
        "    for word in toks:\n",
        "        bpe_tokens = bpe_tokenizer.tokenize(word)\n",
        "        new_words += bpe_tokens        \n",
        "        bpe_masks += [1] + [0] * (len(bpe_tokens) - 1)\n",
        "\n",
        "    return new_words, bpe_masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXa7UUTcD8aP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens,masks=bpe_tokenize(tokenizer,train_text[1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHZoFYH5HPBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def vectorize_ex( texts, label):\n",
        "    label_id=[1 if label == 'pos' else 0 ]\n",
        "    sep_token = '[SEP]'\n",
        "    cls_token = '[CLS]'\n",
        "    pad_token = '[PAD]'\n",
        "\n",
        "    sep_vid = tokenizer.vocab[sep_token]\n",
        "    cls_vid = tokenizer.vocab[cls_token]\n",
        "    pad_vid = tokenizer.vocab[pad_token]\n",
        "\n",
        "\n",
        "\n",
        "    tokens,mask=bpe_tokenize(tokenizer,texts)\n",
        "    tokens=tokens[:512]\n",
        "    mask=mask[:512]\n",
        "  \n",
        " \n",
        "\n",
        "    src_txt = [' '.join(sent) for sent in [tokens]]\n",
        "    text = ' {} {} '.format(sep_token, cls_token).join(src_txt)\n",
        "\n",
        "    src_subtokens = tokenizer.tokenize(text)\n",
        "\n",
        "    src_subtokens = [cls_token] + src_subtokens + [sep_token]\n",
        "    src_subtokens=src_subtokens[:511]+ [sep_token]\n",
        "    subtoken_idxs = tokenizer.convert_tokens_to_ids(src_subtokens)\n",
        "    _segs = [-1] + [i for i, t in enumerate(subtoken_idxs) if t == sep_vid]\n",
        "    segs = [_segs[i] - _segs[i - 1] for i in range(1, len(_segs))]\n",
        "    segments_ids = []\n",
        "    for i, s in enumerate(segs):\n",
        "        if (i % 2 == 0):\n",
        "            segments_ids += s * [0]\n",
        "        else:\n",
        "            segments_ids += s * [1]\n",
        "\n",
        "\n",
        "    return subtoken_idxs, segments_ids, mask[:512], label_id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqyMKW7qXuL0",
        "colab_type": "text"
      },
      "source": [
        "answers on questions:\n",
        "\n",
        "a) we and such tokens  '[SEP]','[CLS]','[PAD]'. sep set in begin of sentences, cls in the end\n",
        "\n",
        "b)length of  positional embeddings is 512\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRI-7XgkIfmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels_list=list(train_labels[0])\n",
        "subtoken_idxs, segments_ids, mask, label_id=vectorize_ex(train_text[0],train_labels_list[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kf-qotg4erv-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler, TensorDataset)\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuIrq-TtfZnN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subtoken_idxs_all=[]\n",
        "segments_ids_all=[]\n",
        "mask_all=[]\n",
        "label_id_all=[]\n",
        "for i in (range(len(train_text))):\n",
        "  subtoken_idxs, segments_ids, mask, label_id=vectorize_ex(train_text[i],train_labels_list[i])\n",
        "  subtoken_idxs_all.append(subtoken_idxs)\n",
        "  segments_ids_all.append(segments_ids)\n",
        "  mask_all.append(mask)\n",
        "  label_id_all.append(label_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7Hs-9JRg0eV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subtoken_idxs_all_=torch.tensor(subtoken_idxs_all)\n",
        "mask_all_=torch.tensor(mask_all)\n",
        "segments_ids_all_=torch.tensor(segments_ids_all)\n",
        "label_id_all_=torch.tensor(label_id_all)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySzWEZV7wy_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = TensorDataset(subtoken_idxs_all_, mask_all_, label_id_all_)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W8yTMIVfT36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "class BertBinaryClassifier(nn.Module):\n",
        "    def __init__(self, dropout=0.1):\n",
        "        super(BertBinaryClassifier, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.linear = nn.Linear(768, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, tokens,mask):\n",
        "        _, pooled_output = self.bert(tokens,attention_mask=mask)\n",
        "        linear_output = self.linear(pooled_output)\n",
        "        proba = self.sigmoid(linear_output)\n",
        "        return proba"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9GgvP27sbUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_clf = BertBinaryClassifier().cuda()\n",
        "\n",
        "optimizer = optim.Adam(bert_clf.parameters(), lr=3e-6)\n",
        "loss_func = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sf6oY5H9-vBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9hYv7OsspXx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "348e6dae-160b-4ce9-c61e-65cfd34e9bce"
      },
      "source": [
        "accuracy_tot=[]\n",
        "loss_tot=[]\n",
        "for epoch_num in range(2):\n",
        "    bert_clf.train(True)\n",
        "    loss_epoch=[]\n",
        "    accuracy_epoch=[]\n",
        "    for ids,mask,lab in tqdm(train_dataloader):\n",
        "        # token_ids, labels = tuple(t.to(device) for t in batch_data)\n",
        "        ids=ids.cuda()\n",
        "        mask=mask.cuda()\n",
        "        lab=lab.cuda()\n",
        "        probas = bert_clf(ids,mask)\n",
        "        loss_func = nn.BCELoss()\n",
        "        \n",
        "        batch_loss = loss_func(probas, lab.float())\n",
        "        bert_clf.zero_grad()\n",
        "        batch_loss.backward()\n",
        "        optimizer.step()\n",
        "        acc=accuracy_score(probas.detach().cpu().numpy().round(),lab.detach().cpu().numpy())\n",
        "        loss_epoch.append(batch_loss.detach().cpu().numpy())\n",
        "        accuracy_epoch.append(acc)\n",
        "    bert_clf.train(False)\n",
        "    accuracy_tot.append(np.mean(accuracy_epoch))\n",
        "    loss_tot.append(np.mean(loss_epoch))\n",
        "    print(accuracy_tot[-1])\n",
        "\n",
        "        "
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3750/3750 [17:30<00:00,  3.57it/s]\n",
            "  0%|          | 0/3750 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8514\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3750/3750 [17:31<00:00,  3.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLnUmxT3Rv0G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "c31e0a83-d4e6-40ef-9e3c-1cdebec92b2b"
      },
      "source": [
        "plt.subplot(211)\n",
        "plt.plot(accuracy_tot)\n",
        "plt.title('accuracy')\n",
        "plt.subplot(221)\n",
        "plt.semilogy(loss_tot)\n",
        "plt.title('loss')"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'loss')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEICAYAAACj2qi6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZv8/+A2D2gLYVLAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i5E_PFVUBOkC",
        "colab": {}
      },
      "source": [
        "def bert_features(text,labels_list): \n",
        "  subtoken_idxs_all=[]\n",
        "  segments_ids_all=[]\n",
        "  mask_all=[]\n",
        "  label_id_all=[]\n",
        "  for i in (range(len(text))):\n",
        "    subtoken_idxs, segments_ids, mask, label_id=vectorize_ex(text[i],labels_list[i])\n",
        "    subtoken_idxs_all.append(subtoken_idxs)\n",
        "    segments_ids_all.append(segments_ids)\n",
        "    mask_all.append(mask)\n",
        "    label_id_all.append(label_id)\n",
        "  return subtoken_idxs_all,segments_ids_all,mask_all,label_id_all\n",
        "dev_labels_list=dev_labels[0].tolist()\n",
        "dev_labels_b_list=dev_labels_b[0].tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPzHHwf4-wSN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#make bert tokens for dev and dev_b\n",
        "subtoken_idxs_all_dev,segments_ids_all_dev,mask_all_dev,label_id_all_dev=bert_features(dev,dev_labels_list)\n",
        "subtoken_idxs_all_dev_b,segments_ids_all_dev_b,mask_all_dev_b,label_id_all_dev_b=bert_features(dev_b,dev_labels_b_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE48q9VR-z2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model,subtoken_idxs_all,mask_all,segments_ids_all):\n",
        "  subtoken_idxs_all_=torch.tensor(subtoken_idxs_all)\n",
        "  mask_all_=torch.tensor(mask_all)\n",
        "  segments_ids_all_=torch.tensor(segments_ids_all)\n",
        "  # label_id_all_=torch.tensor(label_id_all)\n",
        "\n",
        "  train_data = TensorDataset(subtoken_idxs_all_, mask_all_)\n",
        "  \n",
        "  train_dataloader = DataLoader(train_data, batch_size=4)\n",
        "  model.eval()\n",
        "  preds=[]\n",
        "  for ids,mask in tqdm(train_dataloader):\n",
        "    # token_ids, labels = tuple(t.to(device) for t in batch_data)\n",
        "    ids=ids.cuda()\n",
        "    mask=mask.cuda()\n",
        "    # lab=lab.cuda()\n",
        "    probas = model(ids,mask)\n",
        "    preds.append(probas.detach().cpu().numpy().round())\n",
        "  preds=np.concatenate(preds)\n",
        "  return preds\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVRXM-MTR55y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7481250f-e53f-4482-cef5-2e9c8b9a9d71"
      },
      "source": [
        "y_pred_train=predict(bert_clf,subtoken_idxs_all,mask_all,segments_ids_all)\n",
        "y_pred_train_dev=predict(bert_clf,subtoken_idxs_all_dev,mask_all_dev,segments_ids_all_dev)\n",
        "y_pred_train_dev_b=predict(bert_clf,subtoken_idxs_all_dev_b,mask_all_dev_b,segments_ids_all_dev_b)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3750/3750 [04:59<00:00, 12.49it/s]\n",
            "100%|██████████| 2500/2500 [03:19<00:00, 12.51it/s]\n",
            "100%|██████████| 500/500 [00:39<00:00, 12.52it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK6sEtSgSQqp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5mT4eZSYekX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels_=train_labels[0].replace(['neg','pos'],[0,1])\n",
        "dev_labels_=dev_labels[0].replace(['neg','pos'],[0,1])\n",
        "dev_labels_b_=dev_labels_b[0].replace(['neg','pos'],[0,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUnz3xo5Y7Y4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3eb2bd09-0b54-4edb-fe19-fec0fcbf3ac0"
      },
      "source": [
        "print('train accuracy',accuracy_score(y_pred_train,train_labels_))\n",
        "print('dev accuracy',accuracy_score(y_pred_train_dev,dev_labels_))\n",
        "print('dev_v accuracy',accuracy_score(y_pred_train_dev_b,dev_labels_b_))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train accuracy 0.9606666666666667\n",
            "dev accuracy 0.9071\n",
            "dev_v accuracy 0.771\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIk3YmpBoid1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# functions for making bert tokens without labels\n",
        "def vectorize_ex( texts):\n",
        "   \n",
        "    sep_token = '[SEP]'\n",
        "    cls_token = '[CLS]'\n",
        "    pad_token = '[PAD]'\n",
        "\n",
        "    sep_vid = tokenizer.vocab[sep_token]\n",
        "    cls_vid = tokenizer.vocab[cls_token]\n",
        "    pad_vid = tokenizer.vocab[pad_token]\n",
        "\n",
        "\n",
        "\n",
        "    tokens,mask=bpe_tokenize(tokenizer,texts)\n",
        "    tokens=tokens[:512]\n",
        "    mask=mask[:512]\n",
        "  \n",
        " \n",
        "\n",
        "    src_txt = [' '.join(sent) for sent in [tokens]]\n",
        "    text = ' {} {} '.format(sep_token, cls_token).join(src_txt)\n",
        "\n",
        "    src_subtokens = tokenizer.tokenize(text)\n",
        "\n",
        "    src_subtokens = [cls_token] + src_subtokens + [sep_token]\n",
        "    src_subtokens=src_subtokens[:511]+ [sep_token]\n",
        "    subtoken_idxs = tokenizer.convert_tokens_to_ids(src_subtokens)\n",
        "    _segs = [-1] + [i for i, t in enumerate(subtoken_idxs) if t == sep_vid]\n",
        "    segs = [_segs[i] - _segs[i - 1] for i in range(1, len(_segs))]\n",
        "    segments_ids = []\n",
        "    for i, s in enumerate(segs):\n",
        "        if (i % 2 == 0):\n",
        "            segments_ids += s * [0]\n",
        "        else:\n",
        "            segments_ids += s * [1]\n",
        "\n",
        "\n",
        "    return subtoken_idxs, segments_ids, mask\n",
        "\n",
        "def bert_features_test(text): \n",
        "  subtoken_idxs_all=[]\n",
        "  segments_ids_all=[]\n",
        "  mask_all=[]\n",
        "  \n",
        "  for i in (range(len(text))):\n",
        "    subtoken_idxs, segments_ids, mask=vectorize_ex(text[i])\n",
        "    subtoken_idxs_all.append(subtoken_idxs)\n",
        "    segments_ids_all.append(segments_ids)\n",
        "    mask_all.append(mask)\n",
        "\n",
        "  return subtoken_idxs_all,segments_ids_all,mask_all\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQdSCL9eqHeU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "03661f93-3101-46fa-b96f-27233da32dfc"
      },
      "source": [
        "subtoken_idxs_all_test,segments_ids_all_test,mask_all_test=bert_features_test(test)\n",
        "subtoken_idxs_all_test_b,segments_ids_all_test_b,mask_all_test_b=bert_features_test(test_b)\n",
        "\n",
        "y_pred_test=predict(bert_clf,subtoken_idxs_all_test,mask_all_test,segments_ids_all_test)\n",
        "y_pred_train_test_b=predict(bert_clf,subtoken_idxs_all_test_b,mask_all_test_b,segments_ids_all_test_b)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2150/2150 [02:51<00:00, 12.93it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDiuHVUvrhoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "226de910-7e45-4174-dd06-4163645fc589"
      },
      "source": [
        "def to_df(predictions):    \n",
        "    dataframes=[]\n",
        "    tokens=[train_text,dev,test,dev_b,test_b]\n",
        "    names=['train/','dev/','test/','dev-b/','test-b/']\n",
        "    for token,name,pred in tqdm(zip(tokens,names,predictions)):\n",
        "        first_column=[]\n",
        "        for i in range(len(token)):\n",
        "            first_column.append(name+str(i))\n",
        "        df = pd.DataFrame([first_column,pred]).T\n",
        "        dataframes.append(df)\n",
        "    result=pd.concat(dataframes,ignore_index=True) \n",
        "    result[1]=result[1].replace([0,1],['neg','pos'])\n",
        "    return result\n",
        "preds=[y_pred_train,y_pred_train_dev,y_pred_test,y_pred_train_dev_b,y_pred_train_test_b]\n",
        "result=to_df(preds)\n",
        "result.to_csv('file5.tsv',index=False,header=False,sep='\\t')"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5it [00:05,  1.10s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDcF0PpQ2_Rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}